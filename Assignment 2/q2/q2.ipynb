{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi class logistic regression Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZacRtC_OUPq",
        "outputId": "b18d6481-4f2f-4fcf-b114-f602229b8190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.7.0.post1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.18.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPZIRCwOIqOV"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import nd, autograd, gluon\n",
        "import matplotlib.pyplot as plt \n",
        "mx.random.seed(1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHCRApNlOP34"
      },
      "source": [
        "data_ctx = mx.cpu()\n",
        "model_ctx = mx.cpu()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJfsWcHMOd5K"
      },
      "source": [
        "def transform(data, label):\n",
        "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
        "mnist_train = gluon.data.vision.MNIST(train=True, transform=transform).filter(lambda label: label[-1] in [0,1,2,3,4])\n",
        "mnist_test = gluon.data.vision.MNIST(train=False, transform=transform).filter(lambda label: label[-1] in [0,1,2,3,4])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-S04kPhOgTC"
      },
      "source": [
        "image, label = mnist_train[0]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph7ouxAbOqcp"
      },
      "source": [
        "num_inputs = 784\n",
        "num_outputs = 5\n",
        "num_examples = len(mnist_train)+len(mnist_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP1J9FH6Os_l"
      },
      "source": [
        "im = mx.nd.tile(image, (1,1,3))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It5k36jeOxmB"
      },
      "source": [
        "batch_size = 128\n",
        "train_data = mx.gluon.data.DataLoader(mnist_train, batch_size, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3dFwyCUO4Z9"
      },
      "source": [
        "test_data = mx.gluon.data.DataLoader(mnist_test, batch_size, shuffle=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMRsc1L8O6HJ"
      },
      "source": [
        "W = nd.random_normal(shape=(num_inputs, num_outputs),ctx=model_ctx)\n",
        "b = nd.random_normal(shape=num_outputs,ctx=model_ctx)\n",
        "\n",
        "params = [W, b]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KueGGGrFO75J"
      },
      "source": [
        "for param in params:\n",
        "    param.attach_grad()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0_8YQB_O-cX"
      },
      "source": [
        "def softmax(y_linear):\n",
        "    exp = nd.exp(y_linear-nd.max(y_linear, axis=1).reshape((-1,1)))\n",
        "    norms = nd.sum(exp, axis=1).reshape((-1,1))\n",
        "    return exp / norms"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqaYZ448PFTN"
      },
      "source": [
        "def net(X):\n",
        "    y_linear = nd.dot(X, W) + b\n",
        "    yhat = softmax(y_linear)\n",
        "    return yhat"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwyh0-oXPH_V"
      },
      "source": [
        "def cross_entropy(yhat, y):\n",
        "    return - nd.sum(y * nd.log(yhat+1e-6))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksz5hMokPOUW"
      },
      "source": [
        "def SGD(params, lr):\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnL6cV_iPQ4A"
      },
      "source": [
        "def evaluate_accuracy(data_iterator, net):\n",
        "    numerator = 0.\n",
        "    denominator = 0.\n",
        "    for i, (data, label) in enumerate(data_iterator):\n",
        "        data = data.as_in_context(model_ctx).reshape((-1,784))\n",
        "        label = label.as_in_context(model_ctx)\n",
        "        label_one_hot = nd.one_hot(label, 10)\n",
        "        output = net(data)\n",
        "        predictions = nd.argmax(output, axis=1)\n",
        "        numerator += nd.sum(predictions == label)\n",
        "        denominator += data.shape[0]\n",
        "    return (numerator / denominator).asscalar()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS4mfZ4OPVx0",
        "outputId": "70018e68-5095-4dbe-ca5d-aaa3a7977c6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "learning_rate = .005\n",
        "\n",
        "for e in range(epochs):\n",
        "    cumulative_loss = 0\n",
        "    for i, (data, label) in enumerate(train_data):\n",
        "        data = data.as_in_context(model_ctx).reshape((-1,784))\n",
        "        label = label.as_in_context(model_ctx)\n",
        "        label_one_hot = nd.one_hot(label, 5)\n",
        "        with autograd.record():\n",
        "            output = net(data)\n",
        "            loss = cross_entropy(output, label_one_hot)\n",
        "        loss.backward()\n",
        "        SGD(params, learning_rate)\n",
        "        cumulative_loss += nd.sum(loss).asscalar()\n",
        "\n",
        "\n",
        "    test_accuracy = evaluate_accuracy(test_data, net)\n",
        "    train_accuracy = evaluate_accuracy(train_data, net)\n",
        "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, cumulative_loss/num_examples, train_accuracy, test_accuracy))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Loss: 0.7228378805561101, Train_acc 0.93737745, Test_acc 0.9466822\n",
            "Epoch 1. Loss: 0.2478171465825902, Train_acc 0.95015687, Test_acc 0.95680094\n",
            "Epoch 2. Loss: 0.20657477905479332, Train_acc 0.955419, Test_acc 0.96069276\n",
            "Epoch 3. Loss: 0.1829148658740632, Train_acc 0.95862204, Test_acc 0.96322244\n",
            "Epoch 4. Loss: 0.1677396100820022, Train_acc 0.9604523, Test_acc 0.96205485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fHZ_4U2PchY",
        "outputId": "685eccbe-251a-4062-a1fa-863ab4c17baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "def model_predict(net,data):\n",
        "    output = net(data)\n",
        "    return nd.argmax(output, axis=1)\n",
        "\n",
        "# make a prediction\n",
        "sample_data = mx.gluon.data.DataLoader(mnist_test, 1, shuffle=True)\n",
        "for i, (data, label) in enumerate(sample_data):\n",
        "    data = data.as_in_context(model_ctx)\n",
        "    print(data.shape)\n",
        "    im = nd.transpose(data,(1,0,2,3))\n",
        "    im = nd.reshape(im,(28,1*28,1))\n",
        "    imtiles = nd.tile(im, (1,1,3))\n",
        "\n",
        "    plt.imshow(imtiles.asnumpy())\n",
        "    plt.show()\n",
        "    pred=model_predict(net,data.reshape((-1,784)))\n",
        "    print('prediction:', pred[-1])\n",
        "    break"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prediction: \n",
            "[3.]\n",
            "<NDArray 1 @cpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGxMWJS4hnLa"
      },
      "source": [
        "def compute_confusion_matrix(true, pred):\n",
        "  K = len(np.unique(true)) # Number of classes \n",
        "  result = np.zeros((K, K))\n",
        "  for i in range(len(true)):\n",
        "    result[true[i]][pred[i]] += 1\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}